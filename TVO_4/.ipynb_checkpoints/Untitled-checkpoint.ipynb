{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4b7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6e15c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dictionary_documents/text_rating_final.csv\", delimiter=\";\", \n",
    "                   header=None, index_col=False, usecols=[0,1])\n",
    "data = data.rename(columns = {0: \"text\", 1: \"rating\"})\n",
    "data.dropna(inplace=True)\n",
    "data = data[data['rating'] != ' совершенный']\n",
    "data['rating'] = data['rating'].astype(\"Int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07e377f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не рациональная системность, а интуитивный поз...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Когда возникнут трудности, они тебе не помогут...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Кривая национализация это политический компром...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Такой вид биологического оружия не действует н...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В Эль-Кусейре /к западу от Хомса/ сирийские по...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  rating\n",
       "0  Не рациональная системность, а интуитивный поз...       0\n",
       "1  Когда возникнут трудности, они тебе не помогут...       0\n",
       "2  Кривая национализация это политический компром...      -1\n",
       "3  Такой вид биологического оружия не действует н...      -2\n",
       "4  В Эль-Кусейре /к западу от Хомса/ сирийские по...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05b1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['text'].iloc[:1000], data['rating'][:1000], test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718bde19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    tokens = RegexpTokenizer(r'\\w+').tokenize(string)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"russian\")]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d41ac",
   "metadata": {},
   "source": [
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ff410",
   "metadata": {},
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be817450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = data['text'].iloc[:1000].apply(tokenize)\n",
    "\n",
    "model = Word2Vec(words, vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebae4fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_text_len = min(words.apply(lambda x: len(x)))\n",
    "min_text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c710f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_vec = words.apply(lambda x: np.array([model.wv[word] for word in x[:min_text_len]]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40ff6e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.004977012, 0.007866973, 0.00787337, -0.0040...\n",
       "1       [0.008886005, 0.0016663035, 0.0033848323, 0.00...\n",
       "2       [0.00588346, -0.0020739017, 0.0050357673, 0.00...\n",
       "3       [0.0014542402, 0.010155585, 0.0011152382, -0.0...\n",
       "4       [0.0032784594, 0.009981124, 0.008115054, -0.00...\n",
       "                              ...                        \n",
       "1004    [0.0020395524, 0.00018774561, 0.0030498386, -0...\n",
       "1005    [-0.0044261706, 0.0076282057, -0.0025058396, 0...\n",
       "1006    [-0.00946207, 0.008142503, 0.009441727, 0.0012...\n",
       "1007    [-0.008628812, 0.007820256, -0.005420964, -0.0...\n",
       "1008    [0.0015959925, -0.0038259947, 0.010128955, -0....\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6571c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_x_train, w2v_x_test, w2v_y_train, w2v_y_test = train_test_split(texts_vec, data['rating'][:1000], test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af177212",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_x_train = np.vstack(w2v_x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de4c2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier().fit(w2v_x_train, w2v_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51320a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34b20df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35333333333333333\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(np.vstack(w2v_x_test))\n",
    "score = (predicted == w2v_y_test).sum()/len(predicted)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8421244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация и векторизация\n",
    "count_vect = CountVectorizer(lowercase=True, stop_words=stopwords.words(\"russian\"))\n",
    "x_train_tokens = count_vect.fit_transform(x_train)\n",
    "x_test_tokens = count_vect.transform(x_test)\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
    "#x_test_tfidf = tfidf_transformer.transform(x_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98b8e7ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27942)\t2\n",
      "  (0, 23673)\t1\n",
      "  (0, 16369)\t1\n",
      "  (0, 27524)\t1\n",
      "  (0, 22121)\t1\n",
      "  (0, 11458)\t1\n",
      "  (0, 192)\t1\n",
      "  (0, 5334)\t3\n",
      "  (0, 15191)\t1\n",
      "  (0, 14645)\t1\n",
      "  (0, 22283)\t1\n",
      "  (0, 9678)\t1\n",
      "  (0, 22733)\t1\n",
      "  (0, 17405)\t1\n",
      "  (0, 1556)\t1\n",
      "  (0, 5237)\t1\n",
      "  (0, 14448)\t1\n",
      "  (0, 19448)\t1\n",
      "  (0, 24802)\t1\n",
      "  (0, 19163)\t1\n",
      "  (0, 4556)\t1\n",
      "  (0, 11806)\t1\n",
      "  (0, 17225)\t1\n",
      "  (0, 4434)\t1\n",
      "  (0, 6557)\t1\n",
      "  :\t:\n",
      "  (849, 26621)\t1\n",
      "  (849, 24231)\t3\n",
      "  (849, 8682)\t1\n",
      "  (849, 6683)\t1\n",
      "  (849, 6638)\t1\n",
      "  (849, 23580)\t1\n",
      "  (849, 19307)\t1\n",
      "  (849, 4156)\t1\n",
      "  (849, 213)\t2\n",
      "  (849, 25506)\t1\n",
      "  (849, 16929)\t1\n",
      "  (849, 21107)\t1\n",
      "  (849, 13791)\t1\n",
      "  (849, 41)\t1\n",
      "  (849, 393)\t1\n",
      "  (849, 8750)\t1\n",
      "  (849, 342)\t1\n",
      "  (849, 23614)\t1\n",
      "  (849, 20815)\t1\n",
      "  (849, 23641)\t1\n",
      "  (849, 6433)\t1\n",
      "  (849, 2562)\t1\n",
      "  (849, 18680)\t1\n",
      "  (849, 1199)\t1\n",
      "  (849, 417)\t1\n",
      "Метод векторизации - Мешок слов. Классификатор - Наивный байесовский классификатор, Score - 0.4866666666666667\n",
      "Метод векторизации - Мешок слов. Классификатор - Метод опорных векторов, Score - 0.47333333333333333\n",
      "Метод векторизации - Мешок слов. Классификатор - Дерево решений, Score - 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\"Наивный байесовский классификатор\": MultinomialNB(), \"Метод опорных векторов\":SGDClassifier(), \n",
    "               \"Дерево решений\": DecisionTreeClassifier(), \"Ансамблевый метод(Бустинг)\": GradientBoostingClassifier()}\n",
    "vectorizers = {\"Мешок слов\": CountVectorizer(lowercase=True, stop_words=stopwords.words(\"russian\")), \n",
    "               \"TF-IDF\": TfidfVectorizer(lowercase=True, stop_words=stopwords.words(\"russian\"))}\n",
    "scores = {}\n",
    "for v_name, vectorizer in vectorizers.items():\n",
    "    train_transformed = vectorizer.fit_transform(x_train)\n",
    "    print(train_transformed)\n",
    "    test_transformed = vectorizer.transform(x_test)\n",
    "    scores[v_name] = {}\n",
    "    for c_name, classifier in classifiers.items():\n",
    "        classifier.fit(train_transformed, y_train)\n",
    "        predicted = classifier.predict(test_transformed)\n",
    "        score = (predicted == y_test).sum()/len(predicted)\n",
    "        scores[v_name][c_name] = score\n",
    "        print(f\"Метод векторизации - {v_name}. Классификатор - {c_name}, Score - {score}\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(10)\n",
    "a = np.arange(len(scores['TF-IDF']))\n",
    "width = 0.1\n",
    "\n",
    "names = classifiers.keys()\n",
    "\n",
    "ax.bar(a - width/2, scores['TF-IDF'].values(), label = 'TF-IDF')\n",
    "ax.bar(a + width/2, scores['Мешок слов'].values(), label = 'Мешок слов')\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_xticks(a)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de161ab7",
   "metadata": {},
   "source": [
    "Тональный словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"dictionary_documents/words_all_full_rating.csv\", delimiter=\";\")\n",
    "words.head(5)\n",
    "words.set_index(\"Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = x_train.iloc[0].apply(tokenize)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
